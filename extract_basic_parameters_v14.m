function E = extract_basic_parameters_v14(S,R,min_length)
% This function extracts information from the sequence detection analysis. 
% It requires the output from the sequence detection algoritm
% (S), and the output from the pattern analysis (R).  In addition, a
% min_length parameter is required for some of the analyses (= minimal
% number of ISIs in a sequence).
% 
% The paper entitled "Basal Ganglia Neurons in Healthy and Parkinsonian 
% Primates Produce Recurring Sequences of Spikes" (A. Galvan & T. Wichmann)
% is based on version 13 of this routine. Version 14 was prepared for 
% GitHub release, containing additional comments for prospective users.
% Note that not all parameters generated by this routine were eventually
% used in the published paper.
%
% Written by TW, 2019-2022.

num_rep = S(1).original_data.input.num_rep;
P = find_exact_prob_s(S);

%% 'Global' analysis

% original data
actual_total_range_od = S(1).original_data.global_stat.actual_total_range;  % extract the actual range of sequence lengths from the sequence structure S
SL = zeros(actual_total_range_od,1);                % Vector needed to calculate distribution of sequence lengths
L = {[]};
M = zeros(actual_total_range_od,1);                 % Vector needed to calculate distribution of sequence lengths (same size as SL)
for i = min_length:actual_total_range_od
    SL(i) = length(S(i).original_data.global.S);    % the i-th entry into SL is set to the number of different sequences found of length i
    L{i} = zeros(SL(i),1);                          % Initialize L{i} - a vector of length L(i).
    for j = 1:SL(i)
        L{i}(j) = length(S(i).original_data.global.S{j});   % In L{i}, we store a series of numbers representing the number of repetitions of individual sequences
    end
    M(i) = max(L{i});                               % M is set to the highest number of repetitions of individual sequences of length i.
end

total_number_of_sequences_od = sum(SL);             % the total number of sequences in the original data
distr_of_sequence_lengths_od = SL;                  % the distribution of sequence lengths across all possible lengths
distr_of_sequence_max_reps_od = M;                  % the distribution of maximal repetitions of sequences of a given length
[prop_spikes_in_sequences_od,prop_time_in_sequences_od,~] = proportion_spikes_in_sequences(S,min_length);   % call subfunction to calculate the proportion of spikes in sequences
T_original = extract_time_between_sequence_members_original_data(S,min_length); % call subfunction to calculate inter-sequence times

% stats data
SL = zeros(actual_total_range_od,num_rep);          % redefinition of vector needed to calculate distribution of sequence lengths        
L = {[]};
M = zeros(actual_total_range_od,num_rep);           % redefinition of vector needed to calculate distribution of sequence lengths (same size as SL)

pss = NaN(num_rep,1);                               % spikes in sequences for each of the stat structures containsed in S
pts = NaN(num_rep,1);                               % time in sequences for each of the stat structures contained in S
atr = NaN(num_rep,1);                               % actual total range of sequence lengths for the statistics structure in S
for k = 1:num_rep
    atr(k) = S(1).stat(k).global_stat.actual_total_range;   % set atr value
    for i = min_length:atr(k)
        SL(i,k) = length(S(i).stat(k).global.S);    % set the SL value    
        L{i,k} = zeros(SL(i,k),1);                  % set the L value
        for j = 1:SL(i,k)               
            L{i,k}(j) = length(S(i).stat(k).global.S{j});
        end
        M(i,k) = max(L{i,k});                       % set the M values
    end
end
for k = 1:num_rep                                   % for each set of shuffled data ...
    [pss(k),pts(k),~] = proportion_spikes_in_sequences_stat(S,min_length,k);    % call function to calculate the proportion of spikes in the stat data sequences 
    T_stat(k) = extract_time_between_sequence_members_stat_data(S,min_length,k); % calculate the time between sequence members of the stat data ISIs
end

% The elemental_stats function is used in many of the following assignments.
% This function generates statistics of the shuffled sequences (for example
% 'atr' in the first assignment), and then compares the corresponding value
% from the original data stream ('actual_total_range_od' in the first 
% assignemnt) with these statistical measurements. 
E.actual_total_range_of_sequences.global = elemental_stats(actual_total_range_od,atr);
E.total_number_of_sequences.global = elemental_stats(total_number_of_sequences_od,sum(SL));
E.distr_of_sequence_lengths.global = generate_stat_table(distr_of_sequence_lengths_od,SL);
E.distr_of_sequence_max_reps.global = generate_stat_table(distr_of_sequence_max_reps_od,M);
E.prop_spikes_in_sequences.global = elemental_stats(prop_spikes_in_sequences_od,pss);
E.prop_time_in_sequences.global = elemental_stats(prop_time_in_sequences_od,pts);
E.exact_probs.global = P.global;
E.correspondence_with_bursts.global = identify_correspondence_with_bursts(S,R,min_length);
E.polar_analysis.global = polar_analysis(S);

meanT = NaN(length(T_stat),S(1).original_data.input.original_total_range);
medianT = meanT;
for i = 1:length(T_stat)                % calculate the mean and median of the times between sequence members, based on the stat data
    meanT(i,:) = T_stat(i).mean;
    medianT(i,:) = T_stat(i).median;
end
for i = 1:size(meanT,2)                 % this loop calculates elemental stats (as defined in the subroutine), first means, then medians.  
    asd = meanT(:,i);
    asd = asd(~isnan(asd));
    if isempty(asd)
        asd = meanT(:,i);
    end
    E.separation_of_sequences.global.mean{i} = elemental_stats(T_original.mean(i),asd);
    
    asd = medianT(:,i);
    asd = asd(~isnan(asd));
    if isempty(asd)
        asd = medianT(:,i);
    end
    E.separation_of_sequences.global.median{i} = elemental_stats(T_original.median(i),asd);
end

end

function ES = elemental_stats(od,asd)
% In this function, od = original data, asd = array of stats data.  The
% output structure ES contains parameters that describe the distribution of
% the shuffled ISI parameters in question (asd) with the original data.

ES.original_data = od;
ES.stat_array = asd;
ES.mean = mean(asd);
ES.sd = std(asd);
ES.sem = ES.sd/sqrt(length(asd));
if ES.sd == 0
    if od < ES.mean
        ES.original_z = -inf;
    elseif od > ES.mean
        ES.original_z = inf;
    else
        ES.original_z = 0;
    end
else
    ES.original_z = (od-ES.mean)/ES.sd;
end
ES.median = median(asd);
ES.percentiles_of_stat_array = prctile(asd,0:100);  % note that this includes median of stat data as the 50th percentile 
ES.percentile_rank = percentile_rank_v2(od,asd);    % this is the percentile rank of the original data, compared to the stat array
if ES.mean > 0
    ES.multiple_of_mean = od/ES.mean;
else
    ES.mean = inf;
end
if ES.median > 0
    ES.multiple_of_median = od/ES.median;
else
    ES.median = inf;
end

if isnan(od)
    ES.mean = NaN;
    ES.median = NaN;
    ES.multiple_of_mean = NaN;
    ES.multiple_of_median = NaN;
end

end

function ES = generate_stat_table(od,asd)
% od are the original data, asd is a table with the statistics data. The
% function generates columns of data reflecting how the od stacks up
% against the statistical data.  The first entry in each row is the
% original data point, the second through fourth entry are the mean, SD and
% SEM of the statistical data, the fifth one is the z-score of the original
% data, the sixth one the median of the statistical data, the seventh is
% the multiples of the mean that the od represent, and the eight is the
% multiples of the median. 

if size(asd,1) > size(od,1)
    od = [od;zeros(size(asd,1)-size(od,1),1)];
end

if size(od,1) > size(od,2)
    od = od';
    asd = asd';
end

od = zeropad(od,size(asd,2));                                       % helps to make od and asd equally sized
asd = zeropad(asd,size(od,2));                                      % helps to make od and asd equally sized
ES.original.data = od;
ES.stat.data = asd;
ES.stat.mean = mean(asd);
ES.stat.SD = std(asd);
ES.stat.SEM = ES.stat.SD./(sqrt(size(asd,1)));
ES.stat.median = median(asd);
ES.original.z = (od-ES.stat.mean)./ES.stat.SD;
for i = 1:length(od)
    ES.original.percentile(i) = percentile_rank_v2(od(i),asd(:,i));
end
ES.original.multiple_of_mean = od./ES.stat.mean;
ES.original.multiple_of_median = od./ES.stat.median;
end

function P = percentile_rank_v2(a,C)
% This function percentiles a against C (i.e., states the proportion (in
% percent) of element of vector C that are smaller or equal)

Cs = sort(C);
Ps = find(Cs < a,1,'last'); % how many are smaller?
Pl = find(Cs > a,1,'first'); % how many are larger?

if isempty(Ps) && isempty(Pl)
   Ps = 0.5 * length(C);
   Pl = Ps;
elseif isempty(Ps)      % if a is the smallest number within C
   Ps = 1;          % ... we set Ps to 1
   Pl = Pl-1;       % ... to compensate for the addition to Ps, we subtract 1 from Pl    
elseif isempty(Pl)  % if a is the largest number within C
   Pl = 100;        % ... we set Pl to 100
   Ps = Ps+1;       % ... and compensate for this by adding 1 to Ps 
end

P = 100*((Ps+Pl)/2)/length(C);  % the average of Ps and Pl is divided by the total length, and multiplied by 100

if isnan(a)
    P = NaN;
end
end

%% determine exact probabilities of the occurrence of n repetitions of specific sequence X 
function P = find_exact_prob_s(S)
% 
ISI = S(1).original_data.input.ISI;                             % reconstituting ISIs

% identify largest range of sequences
J  = zeros(1,S(1).original_data.input.original_total_range);    % J is a vector of the length of the range of sequences that was found
for i = S(1).original_data.input.original_total_range:-1:2      % Going backwards through the lengths, down to 2 ...
    if ~isempty(S(i).original_data.global.S{1})                 % ... if sequences of length i were identified
        J(i) = length(S(i).original_data.global.S);             % ... J(i) is set to that length.
    end
end
global_max_i = find(J > 0,1,'last');                            % global_max_i is set to the last index of J that contained values (= longest sequences that were actually found)
P.global.original_data.matrix = NaN(global_max_i,max(J));       % P.global.original_data.matrix is an array of global_max_i x maximal number of sequences size

% repeat the steps above for the in-range variables
J  = zeros(1,S(1).original_data.input.original_total_range);    
for i = S(1).original_data.input.original_total_range:-1:2
    if ~isempty(S(i).original_data.in_range.S{1})
        J(i) = length(S(i).original_data.in_range.S);
    end
end
in_range_max_i = find(J > 0,1,'last');
P.in_range.original_data.matrix = NaN(in_range_max_i,max(J));

% process global data
for i = 2:global_max_i                                          % for all sequence lengths that are available
    if ~isempty(S(i).original_data.global.S{1})                 % if there are any sequences of that length ...
        for j = 1:length(S(i).original_data.global.S)           % ... go through each sequence of that length ...
            P.global.original_data.matrix(i,j) = find_exact_prob(ISI,S(i).original_data.global.S{j}(1),i,length(S(i).original_data.global.S{j}),S(1).original_data.input.thr);    % ... and find the exact probability
        end
    end
end

% initialize output variables for the 'global' case
P.global.original_data.num_st_005 = NaN(1,S(1).original_data.input.original_total_range);     
P.global.original_data.num_st_001 = NaN(1,S(1).original_data.input.original_total_range);
P.global.original_data.prop_st_005 = NaN(1,S(1).original_data.input.original_total_range);
P.global.original_data.prop_st_001 = NaN(1,S(1).original_data.input.original_total_range);
P.global.original_data.mean = NaN(1,S(1).original_data.input.original_total_range);
P.global.original_data.median = NaN(1,S(1).original_data.input.original_total_range);

% populate those vectors that were just generated
for i = 2:global_max_i                                                        % for all sequence lengths that are available ...
    Q = P.global.original_data.matrix(i,:);                                   % ... read entry from P.global.original_data.matrix ... 
    Q = Q(~isnan(Q));                                                         % ... and take those that are not NaN entries ...
    P.global.original_data.num_st_005(i) = length(find(Q < 0.05));            % ... the X.num_st_005 parameter for length i is set to the absolute number of sequences whose probability is less than 0.05 ...
    P.global.original_data.num_st_001(i) = length(find(Q < 0.01));            % ... (same as previous step, using p < 0.01) ...
    P.global.original_data.prop_st_005(i) = length(find(Q < 0.05))/length(Q); % ... find the proportion of sequences that show p < 0.05 ...
    P.global.original_data.prop_st_001(i) = length(find(Q < 0.01))/length(Q); % ... (same as previous step, using p < 0.01) ...
    P.global.original_data.mean(i) = mean(Q);                                 % ... calculate average probability ...
    P.global.original_data.median(i) = median(Q);                             % ... calculate median probability
end

% process in_range_data (identical to processing of global data)
for i = 2:in_range_max_i
    if ~isempty(S(i).original_data.in_range.S{1})
        for j = 1:length(S(i).original_data.in_range.S)
            P.in_range.original_data.matrix(i,j) = find_exact_prob(ISI,S(i).original_data.in_range.S{j}(1),i,length(S(i).original_data.in_range.S{j}),S(1).original_data.input.thr);
        end
    end
end

P.in_range.original_data.num_st_005 = NaN(1,S(1).original_data.input.original_total_range);
P.in_range.original_data.num_st_001 = NaN(1,S(1).original_data.input.original_total_range);
P.in_range.original_data.prop_st_005 = NaN(1,S(1).original_data.input.original_total_range);
P.in_range.original_data.prop_st_001 = NaN(1,S(1).original_data.input.original_total_range);
P.in_range.original_data.mean = NaN(1,S(1).original_data.input.original_total_range);
P.in_range.original_data.median = NaN(1,S(1).original_data.input.original_total_range);
for i = 2:global_max_i
    Q = P.in_range.original_data.matrix(i,:);
    Q = Q(~isnan(Q));
    P.in_range.original_data.num_st_005(i) = length(find(Q < 0.05));
    P.in_range.original_data.num_st_001(i) = length(find(Q < 0.01));
    P.in_range.original_data.prop_st_005(i) = length(find(Q < 0.05))/length(Q);
    P.in_range.original_data.prop_st_001(i) = length(find(Q < 0.01))/length(Q);
    P.in_range.original_data.mean(i) = mean(Q);
    P.in_range.original_data.median(i) = median(Q);
end

% now do the whole thing over again for the stats data

for j = 1: S(1).original_data.input.num_rep
    ISI = S(1).stat(j).input.ISI;                             % reconstituting ISIs

    % identify largest range of sequences
    J  = zeros(1,S(1).original_data.input.original_total_range);    % J is a vector of the length of the range of sequences that was found
    for i = S(1).original_data.input.original_total_range:-1:2      % Going backwards through the lengths, down to 2 ...
        if ~isempty(S(i).stat(j).global.S{1})                 % ... if sequences of length i were identified
            J(i) = length(S(i).stat(j).global.S);             % ... J(i) is set to that length.
        end
    end
    global_max_i = find(J > 0,1,'last');                            % global_max_i is set to the last index of J that contained values (= longest sequences that were actually found)
    P.global.stat(j).matrix = NaN(global_max_i,max(J));                     % P.global.stat(j).matrix is an array of global_max_i x maximal number of sequences size

    % repeat the steps above for the in-range variables
    J  = zeros(1,S(1).original_data.input.original_total_range);    
    for i = S(1).original_data.input.original_total_range:-1:2
        if ~isempty(S(i).stat(j).in_range.S{1})
            J(i) = length(S(i).stat(j).in_range.S);
        end
    end
    in_range_max_i = find(J > 0,1,'last');
    P.in_range.stat(j).matrix = NaN(in_range_max_i,max(J));

    % process global data
    for i = 2:global_max_i                                          % for all sequence lengths that are available
        if ~isempty(S(i).stat(j).global.S{1})                 % if there are any sequences of that length ...
            for k = 1:length(S(i).stat(j).global.S)           % ... go through each sequence of that length ...
                P.global.stat(j).matrix(i,k) = find_exact_prob(ISI,S(i).stat(j).global.S{k}(1),i,length(S(i).stat(j).global.S{k}),S(1).original_data.input.thr);    % ... and find the exact probability
            end
        end
    end

    % initialize output variables for the 'global' case
    P.global.stat(j).num_st_005 = NaN(1,S(1).original_data.input.original_total_range);     
    P.global.stat(j).num_st_001 = NaN(1,S(1).original_data.input.original_total_range);
    P.global.stat(j).prop_st_005 = NaN(1,S(1).original_data.input.original_total_range);
    P.global.stat(j).prop_st_001 = NaN(1,S(1).original_data.input.original_total_range);
    P.global.stat(j).mean = NaN(1,S(1).original_data.input.original_total_range);
    P.global.stat(j).median = NaN(1,S(1).original_data.input.original_total_range);

    % populate those vectors that were just generated
    for i = 2:global_max_i                                                  % for all sequence lengths that are available ...
        Q = P.global.stat(j).matrix(i,:);                                   % ... read entry from P.global.stat(j).matrix ... 
        Q = Q(~isnan(Q));                                                   % ... and take those that are not NaN entries ...
        P.global.stat(j).num_st_005(i) = length(find(Q < 0.05));            % ... the X.num_st_005 parameter for length i is set to the absolute number of sequences whose probability is less than 0.05 ...
        P.global.stat(j).num_st_001(i) = length(find(Q < 0.01));            % ... (same as previous step, using p < 0.01) ...
        P.global.stat(j).prop_st_005(i) = length(find(Q < 0.05))/length(Q); % ... find the proportion of sequences that show p < 0.05 ...
        P.global.stat(j).prop_st_001(i) = length(find(Q < 0.01))/length(Q); % ... (same as previous step, using p < 0.01) ...
        P.global.stat(j).mean(i) = mean(Q);                                 % ... calculate average probability ...
        P.global.stat(j).median(i) = median(Q);                             % ... calculate median probability
    end


    % process in_range_data (identical to processing of global data)
    for i = 2:in_range_max_i
        if ~isempty(S(i).stat(j).in_range.S{1})
            for k = 1:length(S(i).stat(j).in_range.S)
                P.in_range.stat(j).matrix(i,k) = find_exact_prob(ISI,S(i).stat(j).in_range.S{k}(1),i,length(S(i).stat(j).in_range.S{k}),S(1).original_data.input.thr);
            end
        end
    end

    P.in_range.stat(j).num_st_005 = NaN(1,S(1).original_data.input.original_total_range);
    P.in_range.stat(j).num_st_001 = NaN(1,S(1).original_data.input.original_total_range);
    P.in_range.stat(j).prop_st_005 = NaN(1,S(1).original_data.input.original_total_range);
    P.in_range.stat(j).prop_st_001 = NaN(1,S(1).original_data.input.original_total_range);
    P.in_range.stat(j).mean = NaN(1,S(1).original_data.input.original_total_range);
    P.in_range.stat(j).median = NaN(1,S(1).original_data.input.original_total_range);
    for i = 2:in_range_max_i
        Q = P.in_range.stat(j).matrix(i,:);
        Q = Q(~isnan(Q));
        P.in_range.stat(j).num_st_005(i) = length(find(Q < 0.05));
        P.in_range.stat(j).num_st_001(i) = length(find(Q < 0.01));
        P.in_range.stat(j).prop_st_005(i) = length(find(Q < 0.05))/length(Q);
        P.in_range.stat(j).prop_st_001(i) = length(find(Q < 0.01))/length(Q);
        P.in_range.stat(j).mean(i) = mean(Q);
        P.in_range.stat(j).median(i) = median(Q);
    end
end

A = NaN(S(1).original_data.input.num_rep,S(1).original_data.input.original_total_range);
B = NaN(S(1).original_data.input.num_rep,S(1).original_data.input.original_total_range);
C = NaN(S(1).original_data.input.num_rep,S(1).original_data.input.original_total_range);
D = NaN(S(1).original_data.input.num_rep,S(1).original_data.input.original_total_range);
for i = 1:S(1).original_data.input.num_rep
    A(i,:) = P.global.stat(i).median;
    B(i,:) = P.global.stat(i).mean;
    C(i,:) = P.in_range.stat(i).median;
    D(i,:) = P.in_range.stat(i).mean;
end
for i = 1:S(1).original_data.input.original_total_range
    P.global.original_data.median_of_stat_medians(i) =  median(A(~isnan(A(:,i)),i));
    P.global.original_data.mean_of_stat_means(i) =  mean(B(~isnan(B(:,i)),i));
    P.in_range.original_data.median_of_stat_medians(i) =  median(C(~isnan(C(:,i)),i));
    P.in_range.original_data.mean_of_stat_means(i) =  mean(D(~isnan(D(:,i)),i));
end

end

function p = find_exact_prob(ISI,start,seq_len,seq_rep,stat_err)
% This function determines the likelihood that a given sequence
% repetition result is obtained, given the existing ISI distribution.  It
% assumes that ISI values are randomly chosen from the (empirically
% measured) ISI distribution.  The function first calculates the likelihood
% of finding a given ISI within the range determined by stat_err 
% (-stat_err*ISI_value:+stat_err*ISI_value) and then calculates the 
% likelihood for a single sequence of the type that is defined in the input
% arguments to occur. The likelihood of finding the actual number of 
% repetitions of the sequence is then determined using a binomial 
% distribution.

% Input parameters: ISI = original ISI data; start = beginning index of a
% specific sequence; seq_len = length of sequence; seq_rep = number of
% repetitions for this particular sequence; stat_err = error margin used to
% detect sequence ('thr' in some of the other routines).

seq = ISI(start:start+seq_len-1);                               % This is the detected repeating sequence of numbers 
seq_lo = seq*(1-stat_err);                                      % seq_lo contains the lowest values individual sequence entries can have
seq_hi = seq*(1+stat_err);                                      % seq hi contains the highest values individual sequence entries can have 

% Determine the likelihood of finding a single sequence, within the boundaries seq_lo -> seq_hi 
p_s = NaN(seq_len,1);                                           % p_s will contain the likelihood of finding individual members
for i = 1:seq_len                                               % for all members of the sequence ...
    p_s(i) = length(ISI(ISI > seq_lo(i) & ISI < seq_hi(i)));    % ... find the number of ISIs within the entire data stream that are within boundaries set by seq_lo and seq_hi)
end
p_s = p_s/length(ISI);                                          % this vector contains the likelihoods for the individual members of the sequence to occur
prob_of_success = prod(p_s,'all');                              % (approximate) probability for a single sequence to occur. Note that this assumes that the same distribution of ISIs is available for each 'throw of the dice'.

% generate a binomial distribution where we look at (length(ISI)-seq_len repetitions of events that occur with the likelihood of prod(p_s,'all')
num_trials = length(ISI) - seq_len + 1;                         % 'number of trials' for binomial distribution
pd = makedist('Binomial','N',num_trials,'p',prob_of_success);   % generate a probability distribution object (binomial distribution)  
p = pdf(pd,seq_rep);                                            % calculate the actual probability at the single location (seq_rep)

end

%% identify correspondence of sequences and bursts
function C = identify_correspondence_with_bursts(S,R,min_length)
% This function looks at what proportion of 'sequences' are also identified
% as bursts. Note that there will not be any difference between global and
% in_range analyses for this parameter.

ISI = S(1).original_data.input.ISI;                                         % read ISIs
[psis,~,sISI] = proportion_spikes_in_sequences(S,min_length);               % this is a reference stream, containing as many zeros as there are ISIs in ISI - this is for sequences
bISI = false(length(ISI),1);                                                % reference ISI stream for bursts

for i = 1:length(R.burst_decel.burst.begin)                                       % for all bursts ...(i)
    bISI(R.burst_decel.burst.begin(i):R.burst_decel.burst.end(i)) = true; % set the corresponding bISI members to true
end

C.ISI = ISI;
bISI = bISI(1:length(sISI));
C.burst_ISI = bISI;
C.sequence_ISI = sISI;
C.proportion_ISIs_in_sequences = psis;
C.proportion_ISIs_in_bursts = length(find(bISI == true))/length(bISI);
C.overlap_burst_ISIs_with_sequence_ISIs = length(find(sISI == true & bISI == true))/length(find(sISI == true));  % portion of sequence ISIs that are also within bursts
C.overlap_sequence_ISIs_with_burst_ISIs = length(find(sISI == true & bISI == true))/length(find(bISI == true));  % proportion of burst ISIs that are also within sequences

end

function [psis,ptis,sISI] = proportion_spikes_in_sequences(S,min_length)
% This function returns the proportion of spikes (psis) and the proportion
% of time (ptis) in sequences, along with a vector of boolean values in which ISIs that
% are in a sequence are marked with 'true'.

sISI = false(length(S(1).original_data.input.ISI),1);                                           % boolean vector of length ISI, initially set to 'false'
for i = min_length:S(1).original_data.input.original_total_range                                % for all applicable sequence lengths ...
    for k = 1:length(S(i).original_data.global.S)                                               % for all sequences found of this sequence length ...
        for l = 1:length(S(i).original_data.global.S{k})                                        % for all instances of specific sequences ...
            sISI(S(i).original_data.global.S{k}(l):S(i).original_data.global.S{k}(l)+i-1) = true;   % turn the participating ISIs to 'true'
        end
    end
end

psis = length(S(1).original_data.input.ISI(sISI == true))/length(S(1).original_data.input.ISI); % calculate the number of spikes in sequences
ptis = sum(S(1).original_data.input.ISI(sISI == true))/sum(S(1).original_data.input.ISI);       % calculate the total time spent in sequences

end

function [psis,ptis,sISI] = proportion_spikes_in_sequences_stat(S,min_length,num_rep)
% This function returns the proportion of spikes (psis) and the proportion
% of time (ptis) in sequences, along with a vector of boolean values in which ISIs that
% are in a sequence are marked with 'true'. Note that this version differs
% from the non-'stat' version only by the referencing to specific num_rep
% values.

sISI = false(length(S(1).stat(num_rep).input.ISI),1);                                           % boolean vector of length ISI, initially set to 'false'
for i = min_length:S(1).original_data.input.original_total_range                                % for all applicable sequence lengths ...
    for k = 1:length(S(i).stat(num_rep).global.S)                                               % for all sequences found of this sequence length ...
        for l = 1:length(S(i).stat(num_rep).global.S{k})                                        % for all instances of specific sequences ...
            sISI(S(i).stat(num_rep).global.S{k}(l):S(i).stat(num_rep).global.S{k}(l)+i-1) = true;   % turn the participating ISIs to 'true'
        end
    end
end

psis = length(S(1).stat(num_rep).input.ISI(sISI == true))/length(S(1).stat(num_rep).input.ISI); % calculate the number of spikes in sequences
ptis = sum(S(1).stat(num_rep).input.ISI(sISI == true))/sum(S(1).stat(num_rep).input.ISI);       % calculate the total time spent in sequences 

end

%% helper function
function A = remove_duplicates(B)
% this function removes all double entries from array B, and returns the
% result as A

for i = 1:length(B)             % for all entries into B
    indx = find(B == B(i));     % find repetitions of B(n)
    if length(indx) > 1         % if there is more than one entry of B(i)
        B(indx(2:end)) = NaN;   % ... all repetitions are set to NaN
    end        
end
A = B(~isnan(B));               % the output variable is set to all numbers in B that are not NaN
end

function A = zeropad(B,pad_len)
% B is zero-padded to pad_len width

A = B;
if size(B,2)< pad_len
    A = zeros(size(B,1),pad_len);
    for i = 1:size(B,1)
        A(i,1:size(B,2)) = B(i,:);
    end
end
end

function T = extract_time_between_sequence_members_original_data(S,min_length)
% This function calculates the mean, median, SD, and SEM of the durations
% between consecutive sequence members of the same sequence

ISI = S(1).original_data.input.ISI;
T.mean = NaN(S(1).original_data.input.original_total_range,1);
T.median = T.mean;
for i = min_length:S(1).original_data.input.original_total_range                                % for all applicable sequence lengths ...
    meanD = NaN(length(S(i).original_data.global.S),1);
    medianD = meanD;
    for k = 1:length(S(i).original_data.global.S)                                               % for all sequences found of this sequence length ...
        D = NaN(length(S(i).original_data.global.S{k})-1,1);
        for l = 1:length(S(i).original_data.global.S{k})-1                                        % for all instances of specific sequences ...
            D(l) = sum(ISI(S(i).original_data.global.S{k}(l)+i:S(i).original_data.global.S{k}(l+1)-i));
        end
        meanD(k) = mean(D);
        medianD(k) = median(D);
    end
    T.mean(i) = mean(meanD);
    T.median(i) = median(medianD);
end
end
    
function T = extract_time_between_sequence_members_stat_data(S,min_length,num_rep)
% This function calculates the mean, median, SD, and SEM of the durations
% between consecutive sequence members of the same sequence

ISI = S(1).original_data.input.ISI;
T.mean = NaN(S(1).original_data.input.original_total_range,1);
T.median = T.mean;
for i = min_length:S(1).original_data.input.original_total_range                                % for all applicable sequence lengths ...
    meanD = NaN(length(S(i).stat(num_rep).global.S),1);
    medianD = meanD;
    for k = 1:length(S(i).stat(num_rep).global.S)                                               % for all sequences found of this sequence length ...
        D = NaN(length(S(i).stat(num_rep).global.S{k})-1,1);
        for l = 1:length(S(i).stat(num_rep).global.S{k})-1                                        % for all instances of specific sequences ...
            D(l) = sum(ISI(S(i).stat(num_rep).global.S{k}(l)+i:S(i).stat(num_rep).global.S{k}(l+1)-i));
        end
        meanD(k) = mean(D);
        medianD(k) = median(D);    
    end
    T.mean(i) = mean(meanD);
    T.median(i) = median(medianD);
end
end

%% Polar analysis
function PA = polar_analysis(S)
% This function is the single-cell version of the batch_extract_sequences
% routine

L = extract_sequence_isis_v2(S,2);
    
% handling of original data
[ang_or,dist_or] = cart2pol(L.original(:,1),L.original(:,2));
dist_or = dist_or/(sqrt(2) * median(S(1).original_data.input.ISI));  % this normalizes the values to the length of a vector that would result if both members of the sequence had the same length
PA.original.angle.binned = histcounts(ang_or,0:pi/40:pi/2-pi/40,'Normalization','probability'); % the range will be 0 -> pi/2.  If values are pi/4, they are on the diagonal.
PA.original.angle.raw_data = ang_or;
PA.original.angle.bin_center = pi/80:pi/40:pi/2-pi/40-pi/80;
PA.original.distance.binned = histcounts(dist_or,0:0.1:5,'Normalization','probability');
PA.original.distance.raw_data = dist_or; 
PA.original.distance.bin_center = 0.05:0.1:4.95;

% handling of stats data
A_st = [];
D_st = [];
for k = 1:length(L.stat)              % for each repetition of the statistical eval ...
    [ang_st,dist_st] = cart2pol(L.stat{k}(:,1),L.stat{k}(:,2));     % generate polar coordinates (output is an array)
    dist_st = dist_st/(sqrt(2) * median(S(1).original_data.input.ISI)); % normalize the distances
    A_st = [A_st;histcounts(ang_st,0:pi/40:pi/2-pi/40,'Normalization','probability')];  % generate the distribution of angles
    D_st = [D_st;histcounts(dist_st,0:0.1:5,'Normalization','probability')];    % generate distribution of distances
end
PA.stat.angle.binned = median(A_st);                    % calculating median of angle distributions
PA.stat.angle.raw_data = A_st;
PA.stat.angle.bin_center = pi/80:pi/40:pi/2-pi/40-pi/80;
PA.stat.distance.binned = median(D_st);                 % calculating median of distance distributions
PA.stat.distance.raw_data = D_st;
PA.stat.distance.bin_center = 0.05:0.1:4.95;

end

function L = extract_sequence_isis_v2(S,l)
% this will extract the isis of the initial example of sequences across all
% sequences of length l

L.original = NaN(length(S(l).original_data.global.S),l);
for i = 1:length(S(l).original_data.global.S)
    if ~isempty(S(l).original_data.global.S{i})
        L.original(i,:) = S(1).original_data.input.ISI(S(l).original_data.global.S{i}(1):S(l).original_data.global.S{i}(1)+l-1);
    end
end
L.original = L.original(~isnan(L.original(:,1)),:);

for j = 1:length(S(l).stat)
    LS = NaN(length(S(l).stat(j).global.S),l);
    for i = 1:length(S(l).stat(j).global.S)
        if ~isempty(S(l).stat(j).global.S{i})
            LS(i,:) = S(1).stat(j).input.ISI(S(l).stat(j).global.S{i}(1):S(l).stat(j).global.S{i}(1)+l-1);
        end
    end
    LS = LS(~isnan(LS(:,1)),:);
    L.stat{j}(:,:) = LS;
end
end